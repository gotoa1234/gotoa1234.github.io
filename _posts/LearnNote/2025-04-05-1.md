---
layout: default_post
title: "0089. Linux Ubuntu 上使用 Docker Compose 快速部署 Kafka"
excerpt: "C# 學習筆記"
tags: 
- "Docker"
- "Docker-Compose"
- "Container"
- "Ubuntu"
- "Linux"
- "Kafka"
- "Kafka UI"
- "Zookeeper"
---

<div class="summary">
<br/>應用所需：1. Linux Ubuntu (本篇 22.04)
<br/>&emsp;&emsp;&emsp;&emsp;&emsp;2. 已安裝 Docker 
<br/>解決問題：1. 如何在 Ubuntu 上安裝容器化 Kafka、Kafka-UI
<br/>&emsp;&emsp;&emsp;&emsp;&emsp;2. 如何檢視 Kafka 管理介面
<br/>基本介紹：本篇分為 3 部分。
<br/>第一部分：Kafka 介紹
<br/>第二部分：安裝 Zookeeper & Kafka & Kafka-UI 
<br/>第三部分：介紹 Kafka-UI 介面

</div>

<div class="title">
    <br/><hr class="titleinner">
	<span></span>
	<hr class="titleinner"><br/>
</div>

<br/><br/>

<h1>第一部分：Kafka 介紹</h1>

<h2>Step 1：Kafka 基本介紹</h2>
擷取自<a href="https://kafka.apache.org/intro">Kafka 官網-介紹</a>，Kafka 的核心是事件串流
<br/>

``` markdown
Apache Kafka® is an event streaming platform. What does that mean?
Kafka combines three key capabilities so you can implement your use cases for event streaming end-to-end with a single battle-tested solution:

 1. To publish (write) and subscribe to (read) streams of events, including continuous import/export of your data from other systems.
 2. To store streams of events durably and reliably for as long as you want.
 3. To process streams of events as they occur or retrospectively.
 
 And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner. Kafka can be deployed on bare-metal hardware, virtual machines, and containers, and on-premises as well as in the cloud. You can choose between self-managing your Kafka environments and using fully managed services offered by a variety of vendors.
```

<br/> 大意是說：Kafka 會記錄所有推送與接收的事件，並支援歷史回溯。其具備分散式架構、彈性擴展能力，並基於高可用設計。
<br/><br/>


<h2>Step 2：Kafka 特點</h2>
Kafka<a href="https://github.com/apache/kafka">github</a>，並且有以下特點

{:class="table table-bordered"}
| 1. 高吞吐量 | 能夠處理高容量的數據流，每秒處理數百萬條消息 |
| 2. 持久性儲存 | 數據可以持久化到磁盤，提供數據安全性 |
| 3. 分散式架構 | 可以橫向擴展，增加節點來提高處理能力 |
| 4. 容錯性 | 具有高可用性和容錯能力，確保數據不會丟失 |
| 5. 實時處理 | 支持實時數據處理與分析 |
| 6. 企業級傾向 | 支持橫向擴展，因此適合用於企業級消息系統，構建大型專案、產品 |
| 7. 完全開源 | 免費，遵循 Apache 2.0 許可證，代碼庫託管在 GitHub 上 |

<br/>※ Apache 2.0 許可證： 非常寬鬆的開源許可證，可以商業免費使用
<br/><br/>


<h2>Step 3：Kaffka & RabbitMQ 差異 - 設計目標</h2>
RabbitMQ 和 Kafka 雖然都是訊息中介軟體 (Message Broker)，但它們的設計理念、架構和適用場景有很大差異，難以完全取代對方。
<br/>兩者間有以下差異：

{:class="table table-bordered"}
|     | kafka | RabbitMq |
| --- | --- | --- |
| 設計目標         |  設計為分散式事件串流平台，專注於高吞吐量和數據持久性   | 設計為傳統的訊息佇列系統，專注於訊息的可靠投遞   |
| 訊息儲存與處理模型 | "拉" 模型，訊息保留在日誌中，多個消費者可反覆讀取    | "推" 模型，訊息發送到消費者後通常會移除 |
| 性能與擴展性      | 非常高的吞吐量，水平擴展優秀 |  適中的吞吐量，垂直擴展較好   |
| 適用場景         | 1. 處理極高吞吐量 (每秒數百萬條訊息)   | 1. 複雜的路由需求   |
|                 | 2. 需要長期保存事件歷史記錄    | 2. 需要立即處理的較小訊息量    |
|                 | 3. 數據流處理和實時分析    | 3. 需要優先級佇列    |
|                 | 4. 系統之間的數據整合    | 4. 需要訊息確認和複雜的交換類型    |
| 適用企業的規模    | 大型企業/系統的選擇  | 小型企業/系統 | 

<br/><br/>



<h2>Step 4：Kaffka & RabbitMQ 適合規模</h2>
從設計目標上 2 者已經有差異了，更進一步分析一下吞吐量與成本的關係，以及不同規模企業的適用選擇：

{:class="table table-bordered"}
|     | kafka | RabbitMq |
| --- | --- | --- |
| 適用企業的規模   | 大型企業/系統的選擇  | 小型企業/系統 | 
| 原因            | 可以無縫擴展處理能力  | 部署更簡單，單節點即可運行良好 | 
|                | 高吞吐量對大量數據至關重要  | 資源消耗較少  | 
|                | 數據持久化和重播功能適合複雜業務場景   | 運維成本較低 | 
|                | 長期存儲能力適合大型企業的合規和分析需求  | 對於中小規模的消息處理足夠用  | 
|                | 總體擁有成本(TCO)對於大型系統可能反而更低  | 配置更簡單，學習曲線較平緩 | 
| 吞吐量影響      | 為了維持高吞吐量，需要更多的硬體資源  | 適中的吞吐量，耗費資源少，但不容易擴展 | 

<br/>如果資源硬體配備不到位，仍要堅持使用分布式的 Kafka ，那麼將會面臨以下問題：
<br/>※如果只是用來練習對於軟體工程師沒有影響 ; 但對小公司或者隨時有可能中斷的產品，可能造成多餘的成本浪費

{:class="table table-bordered"}
| 效能瓶頸與高延遲 | 1. 消息處理延遲增加，可能導致實時性應用無法正常運作 |  
|                | 2. 生產者寫入速度下降，可能造成上游系統阻塞 |  
|                | 3. 消費者讀取延遲，導致下游處理系統等待時間增加 |  
| 系統不穩定性  | 1. 記憶體不足可能導致 Out of Memory 錯誤 |  
|             | 2. 磁碟 I/O 飽和導致系統響應變慢 |  
|             | 3. Broker 可能意外崩潰或重啟 |  
| 數據問題  | 1. 消息丟失風險增加（如果配置不當） |  
|          | 2. 數據複製延遲，增加數據一致性問題 |  
|          | 3. 可能導致分區重新分配頻繁，進一步消耗系統資源 |  
| 運維挑戰  | 1. 系統故障排查變得更加困難 |  
|          | 2. 維護成本顯著增加 |  
|          | 3. 監控壓力增大 |  

<br/>簡的來說：

``` markdown
Kafka 基於事件串流、分布式高吞吐量設計的，會將所有數據保存，因此基本人力成本 & 學習曲線 & 管理較高
如果產品規模在中大型以上時，遍布多處，這時效益才有明顯的提高。
```

<br/><br/>


<h2>Step 5：Kaffka 商業規格</h2>
但如何定義出自己的產品規模通常需要更客觀的數據，硬體資源是首選，Confluent 平台上有提供<a href="https://docs.confluent.io/platform/current/installation/system-requirements.html">Kafka 硬體需求 - 商業級建議</a>
<br/>※補充：<a href="https://www.rabbitmq.com/production-checklist.html">RabbitMQ 官方文檔中的系統需求部分</a>
<br/>Confluent Platform 各組件的硬體推薦配置：

<br/>一、Broker (Kafka 核心服務) - 最高資源需求 ：

{:class="table table-bordered"}
| 節點數：至少 3 個   |
| 存儲： 12 x 1TB 磁盤，建議將系統盤與 Kafka 存儲分離  | 
| 記憶體：64GB RAM |  
| CPU：雙 12核心處理器（24核心） |


<br/>二、ZooKeeper - 協調服務：

{:class="table table-bordered"}
| 節點數：3-5 個   |
| 存儲：交易日誌 512GB + 2 x 1TB SATA（建議 RAID 10）  | 
| 記憶體：4GB RAM |  
| CPU：2-4 核心 |

<br/>三、KRaft Controller - 新型協調服務（替代 ZooKeeper）：

{:class="table table-bordered"}
| 節點數：3-5 個   |
| 存儲：64GB SSD | 
| 記憶體：4GB RAM |  
| CPU：4 核心 |

<br/>四、Control Center - 管理界面：

{:class="table table-bordered"}
| 正常模式：300GB SSD、32GB RAM、12+ 核心  |
| 輕量模式：128GB SSD、8GB RAM、4+ 核心 | 

<br/>總結說明如下：

``` markdown
完整部署需要至少 10 台伺服器
存儲、記憶體和 CPU 需求都很高，運營成本顯著
```

<br/>如果沒有那麼多伺服器，可以考慮其他省成本方案，未必需要使用分布式的 Kafka。
<br/><img src="https://docs.confluent.io/platform/current/_images/confluentPlatform.png" width="50%" height="50%" />
<br/><br/>






<h1>第二部分：安裝 Zookeeper & Kafka & UI </h1>
<h2>Step 1：Docker-Comopse 檔案說明</h2>
<a href="https://github.com/gotoa1234/MyBlogExample/blob/main/KafkaAspCoreWebExample/docker-compose.yml">docker-compose.yml</a>有以下腳本，分別實現以下 3 個項目的容器化安裝：

{:class="table table-bordered"}
| 項目 | 項目 |
| --- | --- |
| zookeeper | Kafka 分散式協調機制的核心管理，使用 2181 Port |
|           | 重啟策略  unless-stopped (表示故障, Crash 後自動重啟, 除了手動停止 ) |
| kafka     | 訊息中介軟體 (Message Broker)，將訊息推送 zookeeper 管理 |
|           | 使用 9092 Port，並且配置自己的主機位置，綁定的 zookeeper 的 Port  |
|           | 重啟策略  unless-stopped (表示故障, Crash 後自動重啟, 除了手動停止 ) |
| kafka-ui  | 提供 kafka 介面化檢視、操作；對外的 Web 操作是開放 8380 Port  |
|           | 依賴於 zookeeper、kafka 收集這 2 個服務資訊 |


``` yml
version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    restart: unless-stopped

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "test-topic:1:1"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper
    restart: unless-stopped

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8380:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    depends_on:
      - kafka
      - zookeeper
```

<br/>其中這邊的 localhsot 一定要改成自己主機的 IP  EX: 我的內部主機用 192.168.51.100
<br/>否則 Kafka-ui 會無法正確訪問到路徑
<br/>從以下：

``` markdown
KAFKA_ADVERTISED_HOST_NAME: localhost
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
```

<br/>改成以下：

``` markdown
KAFKA_ADVERTISED_HOST_NAME: 192.168.51.100
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT:// 192.168.51.100:9092
```


<br/><br/>


<h2>Step 2：移動上述檔案到 Ubuntu 上 - 執行安裝</h2>
將上述的 docker-comopose.yml 檔案放置到 Ubuntu 主機上
<br/>EX: **/louisTemp/kafka/**
<br/>然後輸入下指令

``` shell
 sudo docker-compose up -d
```

<br/> <img src="/assets/image/LearnNote/2025_04_05/001.png" alt="" width="100%" height="100%" />
<br/>

<br/><br/>

<h2>Step 3：安裝完成 </h2>
安裝完成後會出現以下：
<br/> <img src="/assets/image/LearnNote/2025_04_05/002.png" alt="" width="100%" height="100%" />
<br/><br/>

<h2>Step 4：確保正常 </h2>
可以輸入以下檢查：

``` shell
docker ps -a
```

<br/>或者檢查 Portainer 之類的觀察容器插件，確保正常 Running
<br/> <img src="/assets/image/LearnNote/2025_04_05/003.png" alt="" width="100%" height="100%" />
<br/><br/>


<h2>Step 5：進入 Kfaka-UI - 異常畫面 </h2>
在瀏覽器輸入以下網址(自己的主機 + Port)，登入 Kafka-UI 介面

``` html
http://192.168.51.100:8380
```

<br/>如果出現 Offline 表示異常，通常是 docker-compose.yml 的配置錯誤
<br/> <img src="/assets/image/LearnNote/2025_04_05/004.png" alt="" width="100%" height="100%" />
<br/><br/>


<h2>Step 6：進入 Kfaka-UI - 正常畫面 </h2>
如果正常，應會出現 Online 有 1 至此完成基礎安裝。
<br/> <img src="/assets/image/LearnNote/2025_04_05/005.png" alt="" width="100%" height="100%" />
<br/><br/>






<h1>第三部分：介紹 Kafka-UI 介面</h1>
<h2>Step 1：主流的 Kafka 介面 WebUI 工具</h2>
以下是幾個常見的 Kafka Web-UI 管理工具，其中最好但也最貴的是 Confluent 
<br/>本篇使用的 Kafka-UI

{:class="table table-bordered"}
|     | Kafka UI | Confluent Control Center | CMAK |
| --- | --- | --- | --- |
| 特點 | 開源、現代化的 Kafka 集群管理 | Confluent 官方的企業級管理界面，功能最全面 | 雅虎開發的老牌管理工具 |
| 優勢 | 乾淨現代的界面               | 最完整的集群監控和管理功能                 | 支持主題和分區管理  |
|      | 活躍開發維護                | 企業級支持                               | 提供集群健康狀態 |
|      | 輕鬆管理                    |                                        | 廣泛的社區使用經驗 |
| 成本 | 免費                        |  試用、需付費                            | 免費 |

<br/>

{:class="table table-bordered"}
|     | Kafdrop | Kowl | Kaf (CLI + Web UI) |
| --- | --- | --- | --- |
| 特點 | 輕量級但功能完善的管理界面  | 現代化設計的 UI，專注於用戶體驗              | 結合命令行和 Web UI |
| 優勢 | 容易部署(單一 JAR 檔案)    | 強大的主題消息瀏覽和搜索                    | 輕量級  |
|      | 簡單直觀的界面             | 支持 Protobuf、Avro、JSON Schema 數據格式 | 同時提供 CLI 和 Web 界面 |
|      |                          |  支持 Kafka Connect 管理                 | 適合開發環境 |
| 成本 | 免費                      |  免費                                    | 免費 |

<br/>
<br/><br/>


<h2>Step 2：Kafka-UI 介紹</h2>
以下擷取自<a href="https://docs.kafka-ui.provectus.io/">官網</a>介紹

``` markdown
About
About Kafka-UI

UI for Apache Kafka is a versatile, fast, and lightweight web UI for managing Apache Kafka® clusters. Built by developers, for developers.

The app is a free, open-source web UI to monitor and manage Apache Kafka clusters.

UI for Apache Kafka is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and delivers optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.
```


<br/>簡單說： Kafka-UI 有簡潔的儀表板讓你輕鬆追蹤 Kafka 叢集的關鍵指標，包括 Brokers（代理節點）、Topics（主題）、Partitions（分區）、生產（生產者）、消費（消費者） 等。
<br/> <img src="/assets/image/LearnNote/2025_04_05/007.png" alt="" width="100%" height="100%" />
<br/><br/>


<h2>Step 3：Kafka-UI 介面</h2>
以下是進入後 Broker 管理頁面的

{:class="table table-bordered"}
| Broker Count   | 當前的 Kafka 節點數 |
| Active Controller | 目前最活躍的項目 | 
| Version | 程式版本號  |
| Broker ID | Kafka 在啟動時自動分配(沒有[手動]配置ID時)  |
| Disk Usage | 佔用空間 segment(s) 是指 Kafka 的 Log 切割區段，表示已分割 51 個 Segment  |
| Port | 此 Broker 使用的 Port 號  |
| Host | 此 Broker 指向的主機 |

<br/> Kafka 是為了分布式而設計，因此這個管理介面通常會有大量的 Broker
<br/> <img src="/assets/image/LearnNote/2025_04_05/008.png" alt="" width="100%" height="100%" />
<br/><br/>


<h2>Step 4：Kafka-UI 新建 Topic - 1</h2>
為了測試 Kafka 功能，最快的方式是建立一個 Topic ，如下順序：
<br/> <img src="/assets/image/LearnNote/2025_04_05/009.png" alt="" width="100%" height="100%" />
<br/><br/>

<h2>Step 4：Kafka-UI 新建 Topic - 2</h2>
將相關資訊填入，以下是欄位說明：

{:class="table table-bordered"}
| Topic Name | 主題名稱，唯一識別，不可重複 |
| Partitions | 分區數量 | 
| Replication Factoron | 副本數量，決定每個 Partition 有多少份備份，提高 Kafka 的可用性與容錯能力。 1：無備援  |
| Retention Time | 訊息保留時間，超過時間會自動刪除，預設通常是 7 day，保留愈久磁碟佔用空間愈大  |
| Retention Size | 設定 Kafka 允許的最大訊息存儲容量，超過時會刪除舊訊息。-1:無限制  |
| Cleanup Policy | 決定 Kafka 如何處理舊訊息。  |
|                | delete(預設) : 依照 Retention Time + Retention Size  |
|                | compact : Kafka 只保留最新的 Key 值，適合 Key-Value 存儲（如 資料快取）。 |
|                | delete,compact（混合模式）：先進行壓縮，然後根據時間或大小刪除。 |
| Message Size | 最大訊息大小，定 Kafka 允許的單條訊息最大大小，避免過大訊息影響效能。 |


<br/> <img src="/assets/image/LearnNote/2025_04_05/010.png" alt="" width="100%" height="100%" />
<br/><br/>

<h2>Step 5：Kafka-UI 新建 Topic - 建立完成</h2>
建立完成後，下方會出現 Topic
<br/> <img src="/assets/image/LearnNote/2025_04_05/011.png" alt="" width="100%" height="100%" />
<br/><br/>


<h2>Step 6：Kafka-UI 發送訊息 - 1</h2>
接著可以嘗試進行發送訊息
<br/> <img src="/assets/image/LearnNote/2025_04_05/012.png" alt="" width="100%" height="100%" />
<br/><br/>

<h2>Step 7：Kafka-UI 發送訊息 - 2</h2>
發送內容如下：
<br/> <img src="/assets/image/LearnNote/2025_04_05/013.png" alt="" width="50%" height="50%" />

<br/>其中 Partition 為何要選擇，解釋如下：

``` markdown
Topic 可以擁有多個 Partition。
Partition 可以視為 同一個 Topic 的分片，不同的 Partition 分佈在不同的 Brokers 上，以達到負載均衡的效果。
這樣可以提升系統的並行處理能力，讓多個 Consumer 同時消費不同 Partition 的訊息，提高吞吐量。
此外，Partition 分散在不同的 Brokers 上，提升了容錯能力，即使某個 Partition 異常，其他 Partition 仍能正常運行，使 Kafka 服務不會因單一故障而停止。
```

<br/><br/>

<h2>Step 8：Kafka-UI 成功收到</h2>
最後在 **Message** 的欄位中展開歷史紀錄，可以收到剛剛發出的消息
<br/> <img src="/assets/image/LearnNote/2025_04_05/014.png" alt="" width="100%" height="100%" />
<br/><br/>